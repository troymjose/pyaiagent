# pyaiagent Examples

Welcome to the pyaiagent examples! This directory contains production-quality examples that demonstrate every feature of the library.

## Getting Started

### Prerequisites

```bash
pip install pyaiagent
export OPENAI_API_KEY="sk-..."
```

### Running Examples

Each example is a standalone script:

```bash
# From the project root
python examples/00_basic_agent.py
```

For FastAPI examples:

```bash
pip install fastapi uvicorn
uvicorn examples.06_fastapi_basic:app --reload
```

---

## Example Overview

### Beginner Examples

| File | Description | Key Concepts |
|------|-------------|--------------|
| [`00_basic_agent.py`](00_basic_agent.py) | Your first agent in 10 lines | `OpenAIAgent`, docstrings, `process()` |
| [`01_conversation_memory.py`](01_conversation_memory.py) | Multi-turn conversations | `history`, chat loops |
| [`02_tools_basic.py`](02_tools_basic.py) | Give agents superpowers | `async`/`sync` tools, type hints, docstrings |

### Intermediate Examples

| File | Description | Key Concepts |
|------|-------------|--------------|
| [`03_structured_output.py`](03_structured_output.py) | Typed responses with Pydantic | `text_format`, `output_parsed` |
| [`04_config_advanced.py`](04_config_advanced.py) | All configuration options | `Config` class, temperature, timeouts |
| [`05_dynamic_instructions.py`](05_dynamic_instructions.py) | Runtime personalization | `instruction_params`, placeholders |

### Production Examples

| File | Description | Key Concepts |
|------|-------------|--------------|
| [`06_fastapi_basic.py`](06_fastapi_basic.py) | Simple FastAPI integration | REST API, agent reuse |
| [`07_fastapi_with_lifespan.py`](07_fastapi_with_lifespan.py) | Production FastAPI setup | Lifespan, `shutdown()`, sessions |
| [`08_error_handling.py`](08_error_handling.py) | Comprehensive error handling | Exceptions, logging, patterns |

### Advanced Examples

| File | Description | Key Concepts |
|------|-------------|--------------|
| [`09_inheritance_composition.py`](09_inheritance_composition.py) | Building agent hierarchies | Inheritance, tool reuse, routing |
| [`10_context_manager.py`](10_context_manager.py) | Async context managers | `async with`, cleanup, pipelines |
| [`11_message_formatting.py`](11_message_formatting.py) | Token optimization hooks | `format_history`, `format_event` |
| [`12_dependency_injection.py`](12_dependency_injection.py) | Injecting services via `__init__` | DB clients, API clients, testing |
| [`13_custom_client.py`](13_custom_client.py) | Custom OpenAI client configuration | `set_default_openai_client`, Azure, Ollama, proxies |
| [`14_validation_retries.py`](14_validation_retries.py) | Auto-retry on structured output validation failure | `validation_retries`, `ValidationRetriesExhaustedError`, messages cleanup |

---

## Quick Reference

### Minimal Agent

```python
from pyaiagent import OpenAIAgent

class MyAgent(OpenAIAgent):
    """You are a helpful assistant."""

agent = MyAgent()
result = await agent.process(input="Hello!")
print(result["output"])
```

### Agent with Tools

```python
class ToolAgent(OpenAIAgent):
    """You can use tools to help users."""

    # Async tool: for I/O-bound work (API calls, DB)
    async def get_weather(self, city: str) -> dict:
        """Get weather for a city."""
        return {"city": city, "temp": "22¬∞C"}

    # Sync tool: for CPU-bound work (runs in thread pool)
    def calculate(self, expression: str) -> dict:
        """Evaluate a math expression."""
        return {"result": eval(expression)}
```

### Structured Output

```python
from pydantic import BaseModel

class Response(BaseModel):
    answer: str
    confidence: float

class StructuredAgent(OpenAIAgent):
    """Return structured responses."""

    class Config:
        text_format = Response
```

### Conversation Memory

```python
history = []
for user_input in messages:
    result = await agent.process(
        input=user_input,
        history=history
    )
    history = result["history"]
```

**Two message lists, two purposes:**

- `result["history"]` ‚Äî Full accumulated conversation history. Pass to the next `process()` call for memory. In production, **overwrite** the session record each request. If validation retries occurred, retry artifacts are automatically cleaned ‚Äî only the final valid response remains.
- `result["events"]` ‚Äî Current turn only (enriched with `agent`, `session`, `turn`, `step`, `tokens`). In production, **insert/append** to an events collection each request. If validation retries occurred, all attempts (including failures) are preserved for debugging.

**Production pattern (3 steps ‚Äî load, process, save):**

```python
@app.post("/chat")
async def chat(session_id: str, message: str):
    history = await db.load_session(session_id)        # 1. LOAD

    result = await agent.process(                            # 2. PROCESS
        input=message, session=session_id, history=history
    )

    await db.save_session(session_id, result["history"])    # 3. SAVE (overwrite)
    await db.insert_events(session_id, result["events"])            #    (append)
    return {"response": result["output"]}
```

### Validation Retries (Structured Output)

Auto-retry when custom Pydantic validators fail ‚Äî the LLM gets the errors and self-corrects:

```python
from pydantic import BaseModel, field_validator

class StrictReview(BaseModel):
    title: str
    rating: int

    @field_validator("rating")
    @classmethod
    def must_be_valid(cls, v):
        if not 1 <= v <= 10:
            raise ValueError("Rating must be between 1 and 10")
        return v

class ReviewAgent(OpenAIAgent):
    """You are a movie critic."""

    class Config:
        text_format = StrictReview
        validation_retries = 3  # 0 = disabled (default), for manual retry handling
```

### Message Formatting (Token Optimization)

```python
class MyAgent(OpenAIAgent):
    """You are helpful."""

    class Config:
        text_format = MyOutput  # Has large fields

    def format_history(self, response) -> str:
        # Only store essential content in memory
        if response.output_parsed:
            return response.output_parsed.summary  # Not the large data!
        return response.output_text or ""
```

### Dependency Injection

```python
class MyAgent(OpenAIAgent):
    """You help users with data."""

    def __init__(self, db_client):
        super().__init__()  # Always call super!
        self.db = db_client

    async def get_user(self, user_id: str) -> dict:
        return await self.db.fetch(user_id)

# Usage
agent = MyAgent(db_client=my_database)
```

### Custom OpenAI Client

```python
from openai import AsyncOpenAI
from pyaiagent import set_default_openai_client

# Configure before using any agent
client = AsyncOpenAI(
    api_key="sk-...",
    base_url="https://your-proxy.com/v1",  # Custom endpoint
    timeout=60.0,
    max_retries=3,
)
set_default_openai_client(client)

# Now agents will use this client
agent = MyAgent()
```

### Local LLMs (Ollama)

```python
from openai import AsyncOpenAI
from pyaiagent import set_default_openai_client

client = AsyncOpenAI(
    base_url="http://localhost:11434/v1",
    api_key="ollama",
)
set_default_openai_client(client)

class MyAgent(OpenAIAgent):
    """You are helpful."""
    
    class Config:
        model = "llama3.2"  # Your local model
```

---

## Learning Path

**New to pyaiagent?** Follow this order:

1. **Start here:** `00_basic_agent.py` ‚Äî understand the core concept
2. **Add memory:** `01_conversation_memory.py` ‚Äî multi-turn chats
3. **Add tools:** `02_tools_basic.py` ‚Äî make agents do things
4. **Type safety:** `03_structured_output.py` ‚Äî Pydantic responses
5. **Customize:** `04_config_advanced.py` ‚Äî tune behavior
6. **Go to production:** `07_fastapi_with_lifespan.py` ‚Äî real APIs

**Building something complex?**

- `05_dynamic_instructions.py` ‚Äî personalization
- `08_error_handling.py` ‚Äî robust error handling
- `09_inheritance_composition.py` ‚Äî agent hierarchies
- `11_message_formatting.py` ‚Äî token optimization
- `12_dependency_injection.py` ‚Äî DB/API client injection
- `13_custom_client.py` ‚Äî Azure, Ollama, proxies, custom endpoints

---

## Tips

1. **Start simple** ‚Äî Basic agents work great. Add complexity only when needed.

2. **Reuse agents** ‚Äî In servers, create once and reuse for all requests.

3. **Write good docstrings** ‚Äî The AI reads them. Be specific.

4. **Use type hints** ‚Äî They become the tool parameter schema.

5. **Handle errors** ‚Äî See `08_error_handling.py` for patterns.

6. **Call `shutdown()`** ‚Äî In scripts and on server shutdown, clean up properly.

---

## Instance Variables vs Instruction Params

Understanding when to use `__init__` with instance variables versus `instruction_params` is key to building efficient agents.

### When to Use What

| Approach | Use Case | Example |
|----------|----------|---------|
| **Instance variables (`__init__`)** | Static, per-instance dependencies that don't change between requests | DB connections, API clients, config objects |
| **`instruction_params`** | Dynamic, per-request data that changes with each call | User name, current date, user preferences |
| **Single instance + `instruction_params`** | Same agent behavior, different context per request | Multi-tenant apps, personalized responses |

### Pattern 1: Dependency Injection via `__init__`

Use `__init__` when your agent needs external services or static configuration:

```python
class DatabaseAgent(OpenAIAgent):
    """You are a data assistant. Query the database to help users."""

    def __init__(self, db_connection, cache_client=None):
        super().__init__()  # Always call super().__init__()
        self.db = db_connection
        self.cache = cache_client

    async def query_users(self, user_id: str) -> dict:
        """Look up a user by ID."""
        # Use the injected dependency
        return await self.db.fetch_user(user_id)

# Usage
db = DatabaseConnection("postgresql://...")
agent = DatabaseAgent(db_connection=db)
result = await agent.process(input="Find user #123")
```

### Pattern 2: Per-Request Context via `instruction_params`

Use `instruction_params` for data that changes with each request:

```python
class PersonalizedAgent(OpenAIAgent):
    """
    You are helping {user_name}.
    Their preferences: {preferences}
    Today is {date}.
    """

# Same agent instance, different context per request
agent = PersonalizedAgent()
```

**Placeholder behavior:** By default, unmatched `{placeholders}` are left as-is. This is safe for instructions containing example formats. To require all placeholders:

```python
class StrictAgent(OpenAIAgent):
    """You are helping {user_name}."""

    class Config:
        strict_instruction_params = True  # Raises InstructionKeyError if missing
```

```python
# Request from User A
result = await agent.process(
    input="What should I do today?",
    instruction_params={
        "user_name": "Alice",
        "preferences": "loves hiking",
        "date": "Monday, Jan 13"
    }
)

# Request from User B (same agent instance!)
result = await agent.process(
    input="Suggest a movie",
    instruction_params={
        "user_name": "Bob",
        "preferences": "sci-fi fan",
        "date": "Monday, Jan 13"
    }
)
```

### Pattern 3: Single Instance for Production

For web servers, create **one agent instance** and reuse it for all requests:

```python
from contextlib import asynccontextmanager
from fastapi import FastAPI

class AssistantAgent(OpenAIAgent):
    """You help users with {task_type}."""

    def __init__(self, api_client):
        super().__init__()
        self.api = api_client  # Shared across all requests

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Create ONCE at startup
    app.state.agent = AssistantAgent(api_client=MyAPIClient())
    yield
    await shutdown()

app = FastAPI(lifespan=lifespan)

@app.post("/chat")
async def chat(request: ChatRequest, req: Request):
    agent = req.app.state.agent  # Reuse the same instance
    
    # Customize per-request with instruction_params
    return await agent.process(
        input=request.message,
        instruction_params={"task_type": request.task_type}
    )
```

### Decision Guide

**Use `__init__` + instance variables when:**
- You need database connections, API clients, or external services
- The dependency is expensive to create (connection pools, clients)
- The data is the same for all requests from this agent instance

**Use `instruction_params` when:**
- Data varies per request (user info, current time, context)
- You want one agent to serve multiple users/tenants
- The customization is about "what the agent knows" not "what it can do"

**Use a single instance when:**
- Running in a web server (FastAPI, etc.)
- All requests share the same tools and dependencies
- You want efficient resource usage

**Use multiple instances when:**
- Different instances need different injected dependencies
- You're testing with mock dependencies
- Instances need isolated state (rare)

---

## Need Help?

- üìñ [Full documentation](../README.md)
- üêõ [Report issues](https://github.com/troymjose/pyaiagent/issues)
- üí¨ Questions? Open a discussion!

Happy building! üöÄ

